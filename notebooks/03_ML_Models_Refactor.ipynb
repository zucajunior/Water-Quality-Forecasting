{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a53adbb-df3a-4c55-a72b-467827d9fe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes FeatureConfig e ModelConfig definidas.\n",
      "\n",
      "Configurações de features e modelos prontas para o experimento.\n",
      "\n",
      "Carregando e preparando os dados...\n",
      "Dados preparados e divididos.\n",
      "\n",
      "--- Iniciando o Pipeline de Treino e Avaliação ---\n",
      "\n",
      "--- Treinando o modelo: RandomForestRegressor ---\n",
      "  -> MAE Final: 0.0179 | Tempo: 1.74s\n",
      "\n",
      "--- Treinando o modelo: LGBMRegressor ---\n",
      "  -> MAE Final: 0.0230 | Tempo: 0.45s\n",
      "\n",
      "--- Treinando o modelo: XGBRegressor ---\n",
      "  -> MAE Final: 0.0231 | Tempo: 2.16s\n",
      "\n",
      "--- Treinando o modelo: DecisionTreeRegressor ---\n",
      "  -> MAE Final: 0.0258 | Tempo: 0.13s\n",
      "\n",
      "--- Tabela Comparativa Final ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>MAE Final</th>\n",
       "      <th>Tempo de Treino (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>1.738019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>0.454837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.023134</td>\n",
       "      <td>2.161134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.025765</td>\n",
       "      <td>0.133902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Modelo  MAE Final  Tempo de Treino (s)\n",
       "0  RandomForestRegressor   0.017937             1.738019\n",
       "1          LGBMRegressor   0.023034             0.454837\n",
       "2           XGBRegressor   0.023134             2.161134\n",
       "3  DecisionTreeRegressor   0.025765             0.133902"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Bibliotecas ---\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "\n",
    "# --- 1. Definição das Nossas Classes de Configuração ---\n",
    "@dataclass\n",
    "class FeatureConfig:\n",
    "    \"\"\"Um contentor para todas as configurações de engenharia de features.\"\"\"\n",
    "    target_variable: str = 'ph'\n",
    "    lags: List[int] = field(default_factory=lambda: [1, 2, 3, 4, 5, 6, 7, 8, 34, 35, 36, 37, 38, 72])\n",
    "    windows: List[int] = field(default_factory=lambda: [2, 4, 8])\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Um contentor genérico para as configurações do modelo.\"\"\"\n",
    "    model_class: Any\n",
    "    params: Dict[str, Any]\n",
    "\n",
    "print(\"Classes FeatureConfig e ModelConfig definidas.\")\n",
    "\n",
    "# --- 2. Criação da Lista de Configurações para o Experimento ---\n",
    "model_configs = [\n",
    "    ModelConfig(\n",
    "        model_class=RandomForestRegressor,\n",
    "        params={'n_estimators': 100, 'n_jobs': -1, 'random_state': 42} # Usando params padrão, que foram os melhores\n",
    "    ),\n",
    "    ModelConfig(\n",
    "        model_class=lgb.LGBMRegressor,\n",
    "        params={'objective': 'mae', 'n_estimators': 1000, 'n_jobs': -1, 'verbose': -1, 'seed': 42,\n",
    "                'learning_rate': 0.1, 'max_depth': -1, 'num_leaves': 20, 'reg_alpha': 0.5, 'reg_lambda': 0}\n",
    "    ),\n",
    "    ModelConfig(\n",
    "        model_class=xgb.XGBRegressor,\n",
    "        params={'objective': 'reg:squarederror', 'n_estimators': 1000, 'n_jobs': -1, 'seed': 42,\n",
    "                'learning_rate': 0.05, 'max_depth': 7, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
    "    ),\n",
    "    ModelConfig(\n",
    "        model_class=DecisionTreeRegressor,\n",
    "        params={'criterion': 'squared_error', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'random_state': 42}\n",
    "    )\n",
    "]\n",
    "feature_config = FeatureConfig()\n",
    "print(\"\\nConfigurações de features e modelos prontas para o experimento.\")\n",
    "\n",
    "# --- 3. Carregamento e Preparação dos Dados ---\n",
    "print(\"\\nCarregando e preparando os dados...\")\n",
    "caminho_saida_parquet = r'D:\\DOUTORADO\\DOUTORADO_NOTEBOOK_JPY/df_DocFinal2025.parquet'\n",
    "df = pd.read_parquet(caminho_saida_parquet)\n",
    "\n",
    "def create_features_from_config(df, config: FeatureConfig):\n",
    "    df_features = df.copy()\n",
    "    for lag in config.lags:\n",
    "        df_features[f'{config.target_variable}_lag_{lag}'] = df_features[config.target_variable].shift(lag)\n",
    "    for window in config.windows:\n",
    "        df_features[f'{config.target_variable}_rolling_mean_{window}'] = df_features[config.target_variable].rolling(window=window).mean()\n",
    "        df_features[f'{config.target_variable}_rolling_std_{window}'] = df_features[config.target_variable].rolling(window=window).std()\n",
    "    return df_features.dropna()\n",
    "\n",
    "df_featured = create_features_from_config(df, feature_config)\n",
    "FEATURES = [col for col in df_featured.columns if col != feature_config.target_variable]\n",
    "TARGET = feature_config.target_variable\n",
    "X = df_featured[FEATURES]\n",
    "y = df_featured[TARGET]\n",
    "train_size = len(df_featured) - (7 * 24 * 3)\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:]\n",
    "print(\"Dados preparados e divididos.\")\n",
    "\n",
    "# --- 4. Loop de Treino e Avaliação ---\n",
    "results_list = []\n",
    "print(\"\\n--- Iniciando o Pipeline de Treino e Avaliação ---\")\n",
    "\n",
    "for config in model_configs:\n",
    "    model_name = config.model_class.__name__\n",
    "    print(f\"\\n--- Treinando o modelo: {model_name} ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = config.model_class(**config.params)\n",
    "    \n",
    "    # Lógica de treino específica para modelos com early stopping\n",
    "    if model_name in ['LGBMRegressor', 'XGBRegressor']:\n",
    "        fit_params = {'eval_set': [(X_test, y_test)]}\n",
    "        if model_name == 'LGBMRegressor':\n",
    "             fit_params['callbacks'] = [lgb.early_stopping(100, verbose=False)]\n",
    "        else: # XGBoost\n",
    "            model.set_params(early_stopping_rounds=100)\n",
    "            fit_params['verbose'] = False\n",
    "        \n",
    "        model.fit(X_train, y_train, **fit_params)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    # Previsão e Avaliação\n",
    "    prediction = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, prediction)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    results_list.append({\n",
    "        'Modelo': model_name,\n",
    "        'MAE Final': mae,\n",
    "        'Tempo de Treino (s)': end_time - start_time\n",
    "    })\n",
    "    print(f\"  -> MAE Final: {mae:.4f} | Tempo: {end_time - start_time:.2f}s\")\n",
    "\n",
    "# --- 5. Resultados Finais ---\n",
    "final_results_df = pd.DataFrame(results_list).sort_values(by='MAE Final', ascending=True)\n",
    "print(\"\\n--- Tabela Comparativa Final ---\")\n",
    "display(final_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b6ce25-7b6b-465c-ba74-9899591bb1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
